{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "375753da-1c6c-4b02-986a-6e3b185a5869"
    }
   },
   "source": [
    "# Summary\n",
    "The goal of this assignment is to build a classifier to classify some grayscale images of the size 28x28 into a set of categories. The dimension of the original data is large, so you need to be smart on which method you gonna use and perhaps perform a pre-processing step to reduce the amount of computation. Part of your marks will be a function of the performance of your classifier on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "The dataset can be downloaded from Canvas. The dataset consists of a training set of 30,000 examples and a test set of 5,000 examples. They belong to 10 different categories. The validation set is not provided, but you can randomly pick a subset of the training set for validation. The labels of the first 2,000 test examples are given, you will analyse the performance of your proposed method by exploiting the 2,000 test examples. It is NOT allowed to use any examples from the test set for training; or it will be considered as cheating. The rest 3,000 labels of the test set are reserved for marking purpose. <br />\n",
    "Here are examples illustrating sample of the dataset (each class takes one row):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Dataset_image.jpg\" alt=\"DataSet\" title=\"DataSet\" width=\"450\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 classes in total:<br />\n",
    "0 T-shirt/Top<br />\n",
    "1 Trouser<br />\n",
    "2 Pullover<br />\n",
    "3 Dress<br />\n",
    "4 Coat<br />\n",
    "5 Sandal<br />\n",
    "6 Shirt<br />\n",
    "7 Sneaker<br />\n",
    "8 Bag<br />\n",
    "9 Ankle boot <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to load the data\n",
    "There is a data folder with 4 main files (which can be downloaded from Canvas):\n",
    "    1. images_training.h5\n",
    "    2. labels_training.h5\n",
    "    3. images_testing.h5\n",
    "    4. labels_testing_2000.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the hdf5 file and load the data into a numpy array, assuming the **training data files are in the ./data/train** and **testing data file are in ./data/test**. <br /> Use the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then data would be a numpy array of the shape (30000, 784), and\n",
    "label would be a numpy array of the shape (30000, ).\n",
    "The file images_testing.h5 can be loaded in a similar way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "print(os.listdir(\"./data/train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./data/train/images_training.h5','r') as H:\n",
    "    data_train = np.copy(H['datatrain'])\n",
    "with h5py.File('./data/train/labels_training.h5','r') as H:\n",
    "    label_train = np.copy(H['labeltrain'])\n",
    "\n",
    "# using H['datatest'], H['labeltest'] for test dataset.\n",
    "\n",
    "print(data_train.shape,label_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing a sample data. The first example belongs to class 0: T-Shirt/Top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data_train = data_train.reshape((data_train.shape[0], 28, 28))\n",
    "plt.imshow(data_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.title(\"class \" + str(label_train[0]) + \": T-shirt/Top\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to output the prediction\n",
    "Output a file “predicted_labels.h5” that can be loaded in the same way as above. You may use the following code to generate an output file that meets the requirement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# assume output is the predicted labels\n",
    "# (5000,) with h5py.File('predicted_labels.h5','w') as H:\n",
    "H.create_dataset('output',data=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "aca7ed33-2da5-4fbf-a861-8a886f4020a8"
    }
   },
   "source": [
    "We will load the output file using the code for loading data above. It is your responsibility to make sure the output file can be correctly loaded using this code.\n",
    "The performance of your classifier will be evaluated in terms of the top-1 accuracy metric, i.e.<br /><br />\n",
    "<div style=\"text-align: center\"> $$\\text{Accuracy} = \\frac{\\text{Number of correct classifications}}{\\text{Total number of test examples used}} * 100\\%$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1e4a01db-cd92-48f8-bdaa-21c39456cfcb"
    }
   },
   "source": [
    "## Task description\n",
    "\n",
    "This assignment must be submitted in Python3. Although you are allowed to use external libraries for optimisation and linear algebraic calculations, you are NOT allowed to use external libraries for basic pre-processing or classification. For instance, you are allowed to use scipy.optimize for gradient descent or scipy.linalg.svd for matrix decomposition. However, you are NOT allowed to use sklearn.svm for classification (i.e. you have to implement the classifier yourself)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The report must clearly show :\n",
    "    1. Details of your classifier \n",
    "    2. The predicted results from your classifier on test examples\n",
    "    3. Run-time\n",
    "    4. Hardware and software specifications of the computer that you used for performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
